{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flights_NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxtT6DU9TMyt6CEBIesj05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewrya/DS4A---Team-16/blob/main/Flights_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYranE21h-sp",
        "outputId": "d2bba9e8-4248-4cae-c728-a8ac49338588"
      },
      "source": [
        "# Load Google drive where the data and models are stored\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCvP3orkiKo2"
      },
      "source": [
        "# Load packages\n",
        "\n",
        "import sys\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.utils import resample \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_aPxAVGLn0H"
      },
      "source": [
        "random.seed(10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1UxZ1pmimVb"
      },
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/DS4A/2018.csv')\n",
        "#airports = pd.read_csv(r'/content/drive/MyDrive/DS4A/airports.csv')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "eYi7-1URHJkr",
        "outputId": "8a6b564a-16d6-4dca-ea37-51a03673e443"
      },
      "source": [
        "#departure delays by airport (there are more than 5K airports in the US)\n",
        "d_delays_airport = df[['ORIGIN','DEP_DELAY']].groupby(['ORIGIN'])\n",
        "result = [g[1] for g in list(d_delays_airport))[:3]]\n",
        "#d_delays_airport.plot.bar()\n",
        "plt = result.boxplot(subplots=False, rot=45, fontsize=12)\n",
        "#plt.xlabel('Airport')\n",
        "#plt.ylabel('# of Delayed Flights')\n",
        "#plt.title('Delayed Flights by Airport - 2018')\n",
        "plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-10925288d9df>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    result = [g[1] for g in list(d_delays_airport))[:3]]\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6b4MvLTF0P6"
      },
      "source": [
        "# concatenate years\n",
        "# frames = [df1, df2, df3]\n",
        "# result = pd.concat(frames)\n",
        "dataa = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWN4a_h04WOn",
        "outputId": "6f026e0b-48d7-4ca5-c001-cc2e9c14729e"
      },
      "source": [
        "dataa.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7213446, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPpJMLEMFI1h"
      },
      "source": [
        " \n",
        "#dataa = pd.merge(df_airports, airports, on='airport')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx8eMVzN5dLt"
      },
      "source": [
        "# we have to make the date numeric to be fed into the NN\n",
        "dataa['FL_DATE'] = pd.DatetimeIndex(dataa['FL_DATE']).month\n",
        "# geocode airports\n",
        "dataa = dataa.select_dtypes(['number'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjO-YtIwmPl2",
        "outputId": "4ffdc458-48e6-4591-8897-baca19764ead"
      },
      "source": [
        "dataa['DELAY_FLAG'] = dataa['DEP_DELAY'].gt(15)\n",
        "dataa['DELAY_FLAG']=dataa['DELAY_FLAG'].astype('uint8')\n",
        "\n",
        "#dataa['DELAY_FLAG'] = dataa[dataa['DEP_DELAY'] >= 1] = 1\n",
        "\n",
        "#dataa['DELAY_FLAG'] = dataa[is.na(dataa['DEP_DELAY'])] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "328dcn-SOKLi",
        "outputId": "e477970f-b333-4c50-c1d6-012c662dbebc"
      },
      "source": [
        "dataa.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7213446, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2p-Y3PBOW3A"
      },
      "source": [
        "(dataa['DELAY_FLAG'] == 0).sum()/7213446"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTGA_4xL-9yQ",
        "outputId": "e83eb121-7f7b-4825-8736-0e21794cccaf"
      },
      "source": [
        "dataa.DELAY_FLAG.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_20V8oiXeVID"
      },
      "source": [
        "dataa=pd.DataFrame(dataa).fillna(value = -9999999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lyEJH58mqTN",
        "outputId": "e8774777-1637-41c3-9779-fa9d76d9ecb9"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "#create definitions to prepare the data, splitt the data in train and test and scale the data\n",
        "def load_dataset():\n",
        "    dataset = dataa\n",
        "    X = dataset.iloc[:, 0:23].values\n",
        "    y = dataset.iloc[:, 24].values\n",
        "    return X, y\n",
        "def prepare_train_test_set(X, y):\n",
        "    skf=StratifiedKFold(n_splits=2)#, random_state=None, shuffle=False)\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "def scale_features(X_train, X_test):\n",
        "    sc = StandardScaler()\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "    X_test = sc.transform(X_test)\n",
        "    return X_train, X_test\n",
        "#run the data preparation\n",
        "if __name__ == '__main__':\n",
        "    labelencoder_x_1 = LabelEncoder()\n",
        "    dataa.iloc[:, 0] = labelencoder_x_1.fit_transform(dataa.iloc[:, 0])\n",
        "    dataset_path = sys.argv[1]\n",
        "    X, y = load_dataset()\n",
        "    X_train, X_test, y_train, y_test = prepare_train_test_set(X, y)\n",
        "    X_train, X_test = scale_features(X_train, X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [3601258 3601259 3601260 ... 7213443 7213444 7213445] TEST: [      0       1       2 ... 3635380 3635381 3635386]\n",
            "TRAIN: [      0       1       2 ... 3635380 3635381 3635386] TEST: [3601258 3601259 3601260 ... 7213443 7213444 7213445]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pahSAZB5m6CE"
      },
      "source": [
        "#Prepare the earlystop and saved weights\n",
        "filepath = \"model_weights.hdf5\"\n",
        "callbbacks_list = [ModelCheckpoint(filepath, monitor = \"val_loss\", save_best_only = True, mode = \"min\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjPYvPaBm8I9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LaA2_ea8NWu",
        "outputId": "c4230819-9975-4981-b797-1965f097fdc5"
      },
      "source": [
        "nodes_list2 = [1]\n",
        "roc_outcomes = []\n",
        "pr_outcomes = []\n",
        "loss_hx_list = []\n",
        "model_number = np.array(np.arange(1, len(nodes_list2)+1)).tolist()\n",
        "count = 0\n",
        "columns_list = [\"Epochs\"]\n",
        "\n",
        "#Run neural network for all nodes \n",
        "import time \n",
        "start_time = time.time()\n",
        "\n",
        "for nodes in nodes_list2:\n",
        "  count += 1\n",
        "\n",
        "\n",
        "  columns_list.append(\"model \" + str(count))\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"model \" + str(count) + \"/\" + str(len(nodes_list2)))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units = 23,input_dim=23,activation='relu'))\n",
        "  model.add(Dense(units = nodes, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
        "  model.fit(X_train, y_train, validation_split = 0.25, epochs=1, batch_size = 32, callbacks = [EarlyStopping(monitor=\"val_loss\", patience=3)])\n",
        "\n",
        "  #pred_prob = model.predict_prob(X_test)\n",
        "  #predictions = model.predict_classes(X_test) #this is the original code\n",
        "  pred_prob=model.predict(X_test)\n",
        "  #predictions=np.argmax(predict_prob,axis=1)\n",
        "  predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "  logit_roc_out = roc_auc_score(y_test, pred_prob)\n",
        "  average_precision = average_precision_score(y_test, predictions)\n",
        "  roc_outcomes.append(logit_roc_out)\n",
        "  pr_outcomes.append(average_precision)\n",
        "\n",
        "  cm = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
        "  cm[\"Total\"] = np.sum(cm, axis =1)\n",
        "  cm = cm.append(np.sum(cm, axis =0), ignore_index =True)\n",
        "  cm.columns = [\"Predicted No\", \"Predicted Yes\", \"Total\"]\n",
        "  cm = cm.set_index([[\"Actual No\", \"Actual Yes\", \"Total\" ]])\n",
        "  print(\"Model Confusion Matrix\")\n",
        "  print(cm)\n",
        "\n",
        "  print(\"Model Classification Report\")\n",
        "  print(classification_report(y_test, predictions))\n",
        "\n",
        "  elapsed_time = (time.time() - start_time)/60\n",
        "  pct_comp = (count/len(nodes_list2))*100\n",
        "  print(str(round(pct_comp, 2)) + \"% complete\" + \" (Elapsed time = \" + str(round(elapsed_time, 2)) + \" min\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "model 1/1\n",
            "\n",
            "\n",
            "84533/84533 [==============================] - 163s 2ms/step - loss: 0.2360 - binary_accuracy: 0.9244 - val_loss: 0.2448 - val_binary_accuracy: 0.9214\n",
            "Model Confusion Matrix\n",
            "            Predicted No  Predicted Yes    Total\n",
            "Actual No        2808574         166738  2975312\n",
            "Actual Yes        109984         521427   631411\n",
            "Total            2918558         688165  3606723\n",
            "Model Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95   2975312\n",
            "           1       0.76      0.83      0.79    631411\n",
            "\n",
            "    accuracy                           0.92   3606723\n",
            "   macro avg       0.86      0.88      0.87   3606723\n",
            "weighted avg       0.93      0.92      0.92   3606723\n",
            "\n",
            "100.0% complete (Elapsed time = 6.42 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG9LSdTWk_U6"
      },
      "source": [
        "#lf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "#                    hidden_layer_sizes=(5, 2), random_state=1)\n",
        "\n",
        "#clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQ5WoxJ_wav"
      },
      "source": [
        "#plot network accuracy vs epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "l0sGS4GynGCT",
        "outputId": "6a8bf6dc-9e5a-4be4-f5f1-e5e8ee431eb1"
      },
      "source": [
        "# ignore this\n",
        "#create list of nodes that should be tried to find best neural network\n",
        "nodes_list = [10, 20, 30, 40, 50]\n",
        "roc_outcomes = []\n",
        "pr_outcomes = []\n",
        "loss_hx_list = []\n",
        "model_number = np.array(np.arange(1, len(nodes_list)+1)).tolist()\n",
        "count = 0\n",
        "columns_list = [\"Epochs\"]\n",
        "\n",
        "#Run neural network for all nodes \n",
        "import time \n",
        "start_time = time.time()\n",
        "\n",
        "for nodes in nodes_list:\n",
        "  count += 1\n",
        "\n",
        "  try:\n",
        "    columns_list.append(\"model \" + str(count))\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"model \" + str(count) + \"/\" + str(len(nodes_list)))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units = 23,input_dim=23,activation='relu'))\n",
        "    model.add(Dense(units = nodes, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
        "    model.fit(X_train, y_train, validation_split = 0.25, epochs=5, batch_size = 32, callbacks = [EarlyStopping(monitor=\"val_loss\", patience=3)])\n",
        "\n",
        "    #pred_prob = model.predict_proba(X_test)\n",
        "    #predictions = model.predict_classes(X_test)\n",
        "    pred_prob=model.predict(X_test)\n",
        "    predictions=np.argmax(predict_prob,axis=1)\n",
        "\n",
        "    logit_roc_out = roc_auc_score(y_test, pred_prob)\n",
        "    average_precision = average_precision_score(y_test, predictions)\n",
        "    roc_outcomes.append(logit_roc_out)\n",
        "    pr_outcomes.append(average_precision)\n",
        "\n",
        "    cm = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
        "    cm[\"Total\"] = np.sum(cm, axis =1)\n",
        "    cm = cm.append(np.sum(cm, axis =0), ignore_index =True)\n",
        "    cm.columns = [\"Predicted No\", \"Predicted Yes\", \"Total\"]\n",
        "    cm = cm.set_index([[\"Actual No\", \"Actual Yes\", \"Total\" ]])\n",
        "    print(\"Model Confusion Matrix\")\n",
        "    print(cm)\n",
        "\n",
        "    print(\"Model Classification Report\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "    elapsed_time = (time.time() - start_time)/60\n",
        "    pct_comp = (count/len(nodes_list))*100\n",
        "    print(str(round(pct_comp, 2)) + \"% complete\" + \" (Elapsed time = \" + str(round(elapsed_time, 2)) + \" min\")\n",
        "  except Exception:\n",
        "    print(\"Warning\")\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "model 1/5\n",
            "\n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d671c2db50cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#pred_prob = model.predict_proba(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}